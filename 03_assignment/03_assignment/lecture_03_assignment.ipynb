{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Важно!** \n",
    "\n",
    "Домашнее задание состоит из нескольких задач, которые вам нужно решить.\n",
    "*   Баллы выставляются по принципу выполнено/невыполнено.\n",
    "*   За каждую выполненую задачу вы получаете баллы (количество баллов за задание указано в скобках).\n",
    "\n",
    "**Инструкция выполнения:** Выполните задания в этом же ноутбуке (места под решения **КАЖДОЙ** задачи обозначены как **#НАЧАЛО ВАШЕГО РЕШЕНИЯ** и **#КОНЕЦ ВАШЕГО РЕШЕНИЯ**)\n",
    "\n",
    "**Как отправить задание на проверку:** Вам необходимо сохранить ваше решение в данном блокноте и отправить итоговый **файл .IPYNB** в личном сообщении Telegram.\n",
    "\n",
    "**Срок проверки преподавателем:** домашнее задание проверяется **в течение 3 дней после дедлайна сдачи** с предоставлением обратной связи\n",
    "\n",
    "# **Прежде чем проверять задания:**\n",
    "\n",
    "1. Перезапустите **ядро (restart the kernel)**: в меню, выбрать **Ядро (Kernel)**\n",
    "→ **Перезапустить (Restart)**\n",
    "2. Затем **Выполнить** **все ячейки (run all cells)**: в меню, выбрать **Ячейка (Cell)**\n",
    "→ **Запустить все (Run All)**.\n",
    "\n",
    "После ячеек с заданием следуют ячейки с проверкой **с помощью assert.**\n",
    "\n",
    "Если в коде есть ошибки, assert выведет уведомление об ошибке.\n",
    "\n",
    "Если в коде нет ошибок, assert отработает без вывода дополнительной информации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "GEjXq7AVKcO6",
    "outputId": "7ae6cac5-e84b-4510-b267-817c05b9545b"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Перевод с Sequence to Sequence Network и Attention\n",
    "*******************************************************************************\n",
    "https://github.com/pytorch/tutorials/blob/main/intermediate_source/seq2seq_translation_tutorial.py\n",
    "\n",
    "В этом домашнем задании мы будем обучать нейронную сеть переводу с английского на русский.\n",
    "\n",
    "Это стало возможным благодаря простым, но мощным идеям seq2seq <https://arxiv.org/abs/1409.3215 >.\n",
    "Две рекуррентные нейронные сети работают вместе, преобразуя одну последовательность в\n",
    "другую. Сеть кодировщиков преобразует входную последовательность в вектор,\n",
    "а сеть декодеров разворачивает этот вектор в новую последовательность.\n",
    "\"\"\"\n",
    "from IPython.display import Image\n",
    "Image(filename='decoder@2x.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bu08O7e7u-jG"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Чтобы улучшить эту модель, мы будем использовать механизм внимания <https://arxiv.org/abs/1409.0473v7 >,\n",
    "который позволяет декодеру научиться фокусироваться на определенном диапазоне входной последовательности.\n",
    "\n",
    "Рекомендуемые источники:\n",
    "-  https://pytorch.org/ For installation instructions\n",
    "-  :doc:`/beginner/deep_learning_60min_blitz` to get started with PyTorch in general\n",
    "-  :doc:`/beginner/pytorch_with_examples` for a wide and deep overview\n",
    "-  :doc:`/beginner/former_torchies_tutorial` if you are former Lua Torch user\n",
    "-  `Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation <https://arxiv.org/abs/1406.1078>\n",
    "-  `Sequence to Sequence Learning with Neural Networks <https://arxiv.org/abs/1409.3215>\n",
    "-  `Neural Machine Translation by Jointly Learning to Align and Translate <https://arxiv.org/abs/1409.0473>\n",
    "-  `A Neural Conversational Model <https://arxiv.org/abs/1506.05869>\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MTfZetveKcPB"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "1uPGh6wHv68y",
    "outputId": "20a92f52-7e66-4d08-bf7b-73496cc86cfb"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Загрузка файлов данных\n",
    "=======================\n",
    "\n",
    "Данные для этого проекта представляют собой набор из множества тысяч пар перевода с английского на русский.\n",
    "\n",
    "Сайты https://tatoeba.org/ и https://www.manythings.org/anki/ содержат датасеты по языкам\n",
    "\n",
    "Пары английского и русского языков слишком велики для включения в репозиторий, поэтому\n",
    "перед продолжением загрузите файл ``eng-rus.txt``. Файл представляет собой табулированный\n",
    "список пар перевода:\n",
    "\n",
    "I am cold.    Я замерз.\n",
    "\n",
    "#####################################################################\n",
    "Аналогично кодированию символов, используемому в учебниках по символьным RNN,\n",
    "мы будем представлять каждое слово в языке как вектор one-hot, или огромный вектор,\n",
    "состоящий из нулей, за исключением одной единицы (в индексе слова). По сравнению\n",
    "с десятками символов, которые могут существовать в языке, слов намного больше,\n",
    "поэтому вектор кодирования гораздо больше. Мы, однако, обрежем данные,\n",
    "чтобы использовать всего несколько тысяч слов на каждом языке.\n",
    "\"\"\"\n",
    "Image(filename='word-encoding@2x.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xozFfa-tKcPD"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Нам понадобится уникальный индекс для каждого слова, чтобы использовать их в качестве входов и целей\n",
    "для сетей позже. Чтобы отслеживать все это, мы будем использовать вспомогательный класс\n",
    "под названием ``Lang``, который имеет словари word → index (``word2index``) и index → word\n",
    "(``index2word``), а также счетчик каждого слова ``word2count``, который будет использоваться для замены редких слов позже.\n",
    "\"\"\"\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mnlbU8Adv6_e"
   },
   "outputs": [],
   "source": [
    "\"\"\" Все файлы в формате Unicode, для упрощения мы преобразуем символы Unicode в ASCII,\n",
    "приведем все к нижнему регистру и уберем большинство знаков пунктуации.\n",
    "Преобразование Unicode-строки в обычный ASCII благодаря https://stackoverflow.com/a/518232/2809427 \"\"\"\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    # Преобразование Unicode-строки в ASCII, убирая диакритические знаки\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Приведение к нижнему регистру, удаление пробелов в начале и конце строки\n",
    "# замена некоторых знаков препинания на пробел перед ними\n",
    "# замена всех символов, не являющихся буквами, на пробел\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Zа-яА-Я!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GOKm4vlfv7Cu"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Для чтения файла данных мы разделим файл на строки, а затем разделим\n",
    " строки на пары. Файлы представлены в формате lang1 → lang2.\"\"\"\n",
    "\n",
    "def readLangs(lang1, lang2):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open(f'{lang1}-{lang2}.txt', encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines if l.strip()]\n",
    "\n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EC3_HhUFvwjL"
   },
   "outputs": [],
   "source": [
    "\"\"\"Поскольку примеров предложений очень много, и мы хотим обучить\n",
    "что-то быстро, мы обрежем набор данных до относительно коротких и\n",
    "простых предложений. Здесь максимальная длина составляет 10 слов\n",
    "(включая конечные знаки препинания), и мы фильтруем предложения,\n",
    "которые переводятся в форму \"Я\" или \"Он\" и так далее (с учетом\n",
    "ранее замененных апострофов).\"\"\"\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[0].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLczCDw-vwl7",
    "outputId": "38182f4a-89f9-4f99-f1a8-1339ff34c89d"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Полный процесс подготовки данных заключается в следующем:\n",
    "\n",
    "- Прочитать текстовый файл и разбить на строки, разбить строки на пары\n",
    "- Нормализовать текст, фильтровать по длине и содержимому\n",
    "- Составляйте списки слов из парных предложений \"\"\"\n",
    "\n",
    "\n",
    "def prepareData(lang1, lang2):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'rus')\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "rRw1lYlQvwpZ",
    "outputId": "cd580baf-4ed6-4a33-bf61-53c6f5a91557"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The Seq2Seq Model\n",
    "=================\n",
    "\n",
    "Рекуррентная нейронная сеть, или RNN, - это сеть, которая работает с последовательностью и использует свой\n",
    "собственный вывод в качестве входа для последующих шагов.\n",
    "\n",
    "`Сеть последовательности к последовательности <https://arxiv.org/abs/1409.3215>`__, или\n",
    "сеть seq2seq, или `сеть кодировщик-декодировщик\n",
    "<https://arxiv.org/abs/1406.1078>`__, - это модель, состоящая из двух RNN, называемых кодировщиком и декодировщиком.\n",
    "Кодировщик считывает входную последовательность и выводит один вектор, а декодировщик считывает этот вектор,\n",
    "чтобы произвести выходную последовательность.\n",
    "\n",
    "В отличие от предсказания последовательности с использованием одной RNN, где каждый вход соответствует выходу,\n",
    "модель seq2seq освобождает нас от длины и порядка последовательности, что делает ее идеальной для перевода между двумя языками.\n",
    "\n",
    "Рассмотрим предложение ``Je ne suis pas le chat noir`` → ``I am not the black cat``. Большинство слов во входном предложении\n",
    "имеют прямой перевод в выходном предложении, но расположены в слегка различном порядке, например, ``chat noir`` и ``black cat``.\n",
    "Из-за конструкции ``ne/pas`` во входном предложении также на одно слово больше. Было бы трудно создать правильный перевод\n",
    "непосредственно из последовательности входных слов.\n",
    "\n",
    "С помощью модели seq2seq кодировщик создает один вектор, который, в идеальном случае, кодирует \"смысл\" входной последовательности в\n",
    "один вектор - одну точку в некотором N-мерном пространстве предложений.\n",
    "\"\"\"\n",
    "# print(image_to_base64(\"seq2seq.png\"))\n",
    "Image(filename='seq2seq@2x.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "Wp2dF4NCKcPH",
    "outputId": "37861425-5986-4736-fd22-21685cfb859c"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The Encoder (Кодировщик)\n",
    "-----------\n",
    "\n",
    "Кодировщик сети seq2seq - это RNN, который выводит некоторое значение для\n",
    "каждого слова из входного предложения. Для каждого входного слова кодер\n",
    "выводит вектор и скрытое состояние и использует скрытое состояние для\n",
    "следующего входного слова.\"\"\"\n",
    "\n",
    "# print(image_to_base64(\"encoder-network.png\"))\n",
    "Image(filename='encoder-network.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "kycGtRMYKcPI",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4d06598e6a8a1a9dfa9f21b068f1b96",
     "grade": true,
     "grade_id": "cell-66cc5f87b805efd9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Задание:\n",
    "\n",
    "**Цель:**\n",
    "Написать класс `EncoderRNN` для использования в модели seq2seq для задачи машинного перевода.\n",
    "\n",
    "**Требования:**\n",
    "1. В конструкторе класса `__init__`:\n",
    "   - Принимайте параметры `input_size`, `hidden_size` и `dropout_p` (с вероятностью отсева 0.1 по умолчанию).\n",
    "   - Задайте атрибут `hidden_size` для хранения размера скрытого состояния.\n",
    "   - Используйте встроенные слои PyTorch (`nn.Embedding` и `nn.GRU`) для создания эмбеддингов входных данных и слоя GRU.\n",
    "   - параметры при инициализации nn.Embedding: input_size, hidden_size\n",
    "   - параметры при инициализации nn.GRU: hidden_size, hidden_size, batch_first=True\n",
    "   - Включите слой `nn.Dropout` с вероятностью отсева `dropout_p`.\n",
    "\n",
    "   В методе forward:\n",
    "   - Принимайте входные данные input.\n",
    "   - Пропустите эти данные через слои Embedding, GRU и Dropout.\n",
    "   - Верните выход и скрытое состояние.\n",
    "\n",
    "В случае затруднений можно обратиться к:\n",
    "https://github.com/pytorch/tutorials/blob/main/intermediate_source/seq2seq_translation_tutorial.py\n",
    "\"\"\"\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "    raise NotImplementedError() # удалить эту строку в процессе решения\n",
    "    # КОНЕЦ ВАШЕГО РЕШЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "L7vtK0FYvUcm",
    "outputId": "d0ee83a9-da27-40db-e7df-3fa887a9ca6c"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Декодер\n",
    "-----------\n",
    "\n",
    "Декодер - это другой RNN, который принимает выходные векторы кодера и\n",
    "выводит последовательность слов для создания перевода.\"\"\"\n",
    "\n",
    "# print(image_to_base64(\"decoder-network.png\"))\n",
    "Image(filename='decoder-network.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "fmtYJI4GKcPJ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f9816178adc2ce15dcaf7b1f3d0a19c",
     "grade": true,
     "grade_id": "cell-6c819bb7be1539a9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Простой декодер\n",
    "^^^^^^^^^^^^^^\n",
    "\n",
    "В простейшем декодере seq2seq мы используем только последний выходной сигнал кодера.\n",
    "Этот последний вывод иногда называют *контекстным вектором*, поскольку он кодирует\n",
    "контекст из всей последовательности. Этот контекстный вектор используется в качестве\n",
    "начальное скрытое состояние декодера.\n",
    "\n",
    "На каждом шаге декодирования декодеру выдается входной токен и\n",
    "скрытое состояние. Начальный входной токен - это начало строки `<SOS>`\n",
    "токен, и первое скрытое состояние - это вектор контекста (кодировщик\n",
    "последнее скрытое состояние).\n",
    "\n",
    "Задание:\n",
    "\n",
    "**Цель:**\n",
    "Реализовать класс `DecoderRNN` для использования в модели seq2seq для задачи машинного перевода.\n",
    "\n",
    "**Требования:**\n",
    "1. Класс должен наследоваться от `nn.Module`.\n",
    "2. В конструкторе класса `__init__`:\n",
    "   - Принимайте параметры `hidden_size` и `output_size`.\n",
    "   - Используйте встроенные слои PyTorch (`nn.Embedding`, `nn.GRU` и `nn.Linear`) для создания эмбеддингов выходных данных,\n",
    "   слоя GRU и линейного слоя для выходных данных.\n",
    "\n",
    "3. Реализуйте метод `forward`:\n",
    "   - Принимайте `encoder_outputs`, `encoder_hidden` и `target_tensor` (по умолчанию `None`).\n",
    "   - Инициализируйте начальный вход `decoder_input` и скрытое состояние `decoder_hidden`.\n",
    "   - В цикле для каждого временного шага вызывайте метод `forward_step` для обновления `decoder_input` и `decoder_hidden`.\n",
    "   - Собирайте выходные данные `decoder_outputs` в список.\n",
    "   - Если предоставлен `target_tensor`, используйте метод \"принуждения учителя\" (teacher forcing) для обновления `decoder_input`. В противном случае используйте предсказания модели.\n",
    "   - Конкатенируйте список `decoder_outputs` и примените логарифмическую функцию Softmax (`F.log_softmax`).\n",
    "   - Верните `decoder_outputs`, `decoder_hidden` и `None` для согласованности с циклом обучения.\n",
    "\n",
    "4. Реализуйте метод `forward_step`:\n",
    "   - Принимайте `input` и `hidden`.\n",
    "   - Примените эмбеддинги, функцию активации ReLU и слой GRU к `input` и `hidden`.\n",
    "   - Примените линейный слой к полученному выводу.\n",
    "   - Верните `output` и `hidden`.\n",
    "\n",
    "В случае затруднений можно обратиться к:\n",
    "https://github.com/pytorch/tutorials/blob/main/intermediate_source/seq2seq_translation_tutorial.py\n",
    "\"\"\"\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "    raise NotImplementedError() # удалить эту строку в процессе решения\n",
    "    # КОНЕЦ ВАШЕГО РЕШЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 725
    },
    "id": "hY2_dhlZvUiW",
    "outputId": "e8f57492-8872-4ce2-bded-6c7062f13927"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Декодер внимания\n",
    "^^^^^^^^^^^^^^^^^\n",
    "\n",
    "Если между кодером и декодером передается только вектор контекста,\n",
    "то этот единственный вектор несет бремя кодирования всего предложения.\n",
    "\n",
    "Внимание позволяет сети декодера \"фокусироваться\" на другой части\n",
    "выходных данных кодера для каждого шага собственных выходных данных декодера. Сначала\n",
    "мы вычисляем набор *весов внимания*. Они будут умножены на\n",
    "выходные векторы кодера для создания взвешенной комбинации. Результат\n",
    "(называемый в коде `attn_applied`) должен содержать информацию о\n",
    "эту конкретную часть входной последовательности и, таким образом, помочь декодеру\n",
    "выбрать правильные выходные слова.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "Image(filename='1152PYf.png')\n",
    "\n",
    "\"\"\"\n",
    "Вычисление весов внимания выполняется с помощью другого уровня прямой\n",
    "связи `attn`, используя входные данные декодера и скрытое состояние в качестве входных данных.\n",
    "Поскольку в обучающих данных есть предложения всех размеров, чтобы\n",
    "фактически создать и обучить этот слой, мы должны выбрать максимальную\n",
    "длину предложения (входную длину для выходных данных кодера), к которой он может быть применен\n",
    ". Предложения максимальной длины будут использовать все коэффициенты внимания,\n",
    "в то время как в более коротких предложениях будут использоваться только первые несколько.\n",
    "\"\"\"\n",
    "\n",
    "Image(filename='attention-decoder-network.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "Gda9qK4zKcPL",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00d27962b7aef7381a3d45743d39560d",
     "grade": true,
     "grade_id": "cell-5d071dd7fcd07394",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Внимание Богданова, также известное как аддитивное внимание, является широко используемым\n",
    "механизмом внимания в моделях от последовательности к последовательности, особенно в задачах нейронного\n",
    "машинного перевода. Он был введен Богдановым и др. в своей\n",
    "статье <https://arxiv.org/abs/1409.0473 >.\n",
    "Этот механизм внимания использует изученную модель выравнивания для вычисления\n",
    "показателей внимания между скрытыми состояниями кодера и декодера. Он использует\n",
    "нейронную сеть с прямой связью для вычисления оценок выравнивания.\n",
    "\n",
    "Однако существуют альтернативные доступные механизмы внимания, такие как Luong attention,\n",
    "который вычисляет баллы внимания путем вычисления точечного произведения между скрытым состоянием декодера\n",
    "и скрытыми состояниями кодера. Это не связано с нелинейным преобразованием, используемым во внимании Богданова.\n",
    "\n",
    "В этом уроке мы будем использовать внимание Богданова. Однако было бы полезным\n",
    "упражнением изучить возможность модификации механизма внимания для использования длительного внимания.\n",
    "Существуют и другие формы внимания, которые работают по всей длине\n",
    "# ограничение с использованием подхода относительного положения. Читайте о \"местном\n",
    "# внимание\" в книге \"Эффективные подходы к нейронной машине, основанной на внимании\".\n",
    "# Перевод <https://arxiv.org/abs/1508.04025 >\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "**Задание: Реализация Класса BahdanauAttention**\n",
    "\n",
    "**Цель:**\n",
    "Реализовать класс `BahdanauAttention` для использования в модели seq2seq для задачи машинного перевода. Механизм внимания по Бахданау является ключевым компонентом для улучшения качества перевода.\n",
    "\n",
    "**Требования:**\n",
    "1. Класс `BahdanauAttention` должен наследоваться от `nn.Module`.\n",
    "\n",
    "2. В конструкторе класса `__init__`:\n",
    "   - Принимайте параметр `hidden_size`.\n",
    "   - Создайте три линейных слоя PyTorch (`nn.Linear`) под именами `Wa`, `Ua`, и `Va`. Используйте `hidden_size` для определения размерности входов и выходов этих слоев.\n",
    "\n",
    "3. Реализуйте метод `forward`:\n",
    "   - Принимайте два аргумента, `query` и `keys`.\n",
    "   - Выполните следующие шаги:\n",
    "      - Примените линейные преобразования с использованием слоев `Wa` и `Ua` к входам `query` и `keys` соответственно.\n",
    "      - Примените функцию активации tanh к полученным результам.\n",
    "      - Сложите результаты преобразований и примените линейное преобразование через слой `Va`.\n",
    "      - Примените функцию tanh ко всему выражению.\n",
    "      - Уменьшите размерность на последней оси (squeeze) и добавьте размерность в начале (unsqueeze).\n",
    "      - Примените функцию Softmax по последней оси.\n",
    "\n",
    "4. Верните веса внимания (`weights`) и взвешенную сумму ключей (`context`) из метода `forward`.\n",
    "\n",
    "В случае затруднений можно обратиться к:\n",
    "https://github.com/pytorch/tutorials/blob/main/intermediate_source/seq2seq_translation_tutorial.py\n",
    "\"\"\"\n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "    raise NotImplementedError() # удалить эту строку в процессе решения\n",
    "    # КОНЕЦ ВАШЕГО РЕШЕНИЯ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "KRRxF2yhKcPM",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9da755d688282685e39d7ef8f861ae5",
     "grade": true,
     "grade_id": "cell-bbe9127598693d8d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**Задание: Реализация Класса AttnDecoderRNN**\n",
    "\n",
    "**Цель:**\n",
    "Реализовать класс `AttnDecoderRNN` для использования в модели seq2seq для задачи машинного перевода.\n",
    "Этот класс использует механизм внимания по Богданову (`BahdanauAttention`).\n",
    "Существуют и другие формы внимания, которые работают по длине ограничение с использованием\n",
    "подхода относительного положения <https://arxiv.org/abs/1508.04025 >.\n",
    "\n",
    "**Требования:**\n",
    "1. Класс `AttnDecoderRNN` должен наследоваться от `nn.Module`.\n",
    "\n",
    "2. В конструкторе класса `__init__`:\n",
    "   - Принимайте параметры `hidden_size`, `output_size` и `dropout_p` (по умолчанию 0.1).\n",
    "   - Создайте встроенный слой PyTorch (`nn.Embedding`) под именем `embedding` для создания эмбеддингов выходных данных.\n",
    "   - Используйте класс `BahdanauAttention` (`attention`) для создания механизма внимания.\n",
    "   - Создайте слой GRU (`nn.GRU`) с учетом входов и выходов для эмбеддингов и контекста внимания.\n",
    "   - Используйте линейный слой (`nn.Linear`) для создания выходного слоя.\n",
    "   - Включите dropout с вероятностью `dropout_p` после эмбеддингов.\n",
    "\n",
    "3. Реализуйте метод `forward`:\n",
    "   - Принимайте `encoder_outputs`, `encoder_hidden` и `target_tensor` (по умолчанию `None`).\n",
    "   - Инициализируйте начальный вход `decoder_input` и скрытое состояние `decoder_hidden`.\n",
    "   - В цикле для каждого временного шага вызывайте метод `forward_step` для обновления `decoder_input`, `decoder_hidden` и получения весов внимания (`attn_weights`).\n",
    "   - Собирайте выходные данные `decoder_outputs` и веса внимания `attentions` в списки.\n",
    "   - Если предоставлен `target_tensor`, используйте метод \"принуждения учителя\" (teacher forcing) для обновления `decoder_input`. В противном случае используйте предсказания модели.\n",
    "   - Конкатенируйте список `decoder_outputs` и примените логарифмическую функцию Softmax (`F.log_softmax`).\n",
    "   - Верните `decoder_outputs`, `decoder_hidden` и `attentions`.\n",
    "\n",
    "4. Реализуйте метод `forward_step`:\n",
    "   - Принимайте `input`, `hidden` и `encoder_outputs`.\n",
    "   - Примените эмбеддинги с dropout к `input`.\n",
    "   - Переставьте размерности скрытого состояния `hidden` для использования в механизме внимания.\n",
    "   - Вызовите метод `forward` механизма внимания (`BahdanauAttention`) для получения контекста внимания (`context`) и весов внимания (`attn_weights`).\n",
    "   - Объедините эмбеддинги и контекст внимания.\n",
    "   - Примените GRU к объединенному входу и скрытому состоянию.\n",
    "   - Примените линейный слой к выходу GRU.\n",
    "   - Верните `output`, `hidden` и `attn_weights`.\n",
    "\n",
    "В случае затруднений можно обратиться к:\n",
    "https://github.com/pytorch/tutorials/blob/main/intermediate_source/seq2seq_translation_tutorial.py\n",
    "\"\"\"\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "    raise NotImplementedError() # удалить эту строку в процессе решения\n",
    "    # КОНЕЦ ВАШЕГО РЕШЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RjB2LzuovUli"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Обучение\n",
    "========\n",
    "\n",
    "Подготовка обучающих данных\n",
    "-----------------------\n",
    "\n",
    "Для обучения для каждой пары нам понадобится входной тензор (индексы\n",
    "слов во входном предложении) и целевой тензор (индексы слов в\n",
    "целевом предложении). При создании этих векторов мы добавим токен\n",
    "EOS к обеим последовательностям.\n",
    "\"\"\"\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData('eng', 'rus')\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return input_lang, output_lang, train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hw1I6vl8vUnv"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Обучение модели\n",
    "------------------\n",
    "\n",
    "Для обучения мы прогоняем входное предложение через кодировщик и отслеживаем\n",
    "каждый вывод и последнее скрытое состояние. Затем декодеру передается\n",
    "токен `<SOS>` в качестве его первого входного сигнала, а последнее скрытое состояние\n",
    "кодера - в качестве его первого скрытого состояния.\n",
    "\n",
    "\"Принуждение преподавателя\" - это концепция использования реальных целевых выходных данных в качестве\n",
    "каждого следующего входного сигнала, вместо использования предположения декодера в качестве следующего входного сигнала.\n",
    "Использование принудительного использования учителем приводит к ускорению конвергенции, но \"когда используется обученная\n",
    "сеть, она может демонстрировать\n",
    "нестабильность <http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&rep=rep1&type=pdf >`__.\n",
    "\n",
    "Вы можете наблюдать выходные данные сетей, созданных учителем, которые читают с\n",
    "согласованной грамматикой, но далеки от правильного перевода -\n",
    "интуитивно он научился представлять выходную грамматику и может \"\n",
    "уловить\" значение, как только учитель скажет ему первые несколько слов, но он\n",
    "не научился должным образом составлять предложение\n",
    "в первую очередь из перевода.\n",
    "\n",
    "Благодаря свободе, которую дает нам автоград PyTorch, мы можем случайным образом\n",
    "выберите, использовать принудительное использование учителем или нет, с помощью простого оператора if. Очередь\n",
    "`teacher_forcing_ratio`, чтобы использовать его в большем количестве.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mT0UWNRUvUqa"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Это вспомогательная функция для печати прошедшего времени и расчетного\n",
    "оставшегося времени с учетом текущего времени и % прогресса.\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVgkLud0vUtZ"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Весь тренировочный процесс выглядит примерно так:\n",
    "\n",
    "- Запуск таймера\n",
    "- Инициализировать оптимизаторы и критерий\n",
    "- Создать набор обучающих пар\n",
    "- Запустить пустой массив потерь для построения графика\n",
    "\n",
    "Затем мы вызываем `train` и выводим прогресс (%\n",
    "примеров, время на данный момент, расчетное время) и loss.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQjPHTNevUwO"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Построение графиков результатов\n",
    "----------------\n",
    "\n",
    "Построение графика выполняется с помощью matplotlib, используя массив значений потерь\n",
    "`plot_losses` сохранен во время тренировки.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9pVdCP5tvCMO"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Оценка\n",
    "==========\n",
    "\n",
    "Оценка в основном такая же, как и обучение, но здесь нет целевых показателей, поэтому\n",
    "мы просто возвращаем прогнозы декодера самому себе для каждого шага.\n",
    "Каждый раз, когда он предсказывает слово, мы добавляем его в выходную строку, и если он\n",
    "предсказывает токен EOS, мы на этом останавливаемся. Мы также сохраняем\n",
    "выходные данные внимания декодера для последующего отображения.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn\n",
    "\n",
    "\"\"\"\n",
    "Мы можем оценить случайные предложения из обучающего набора и распечатать\n",
    "входные данные, цель и выходные данные, чтобы сделать некоторые субъективные оценки качества:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "tDt1YhcBvCPY",
    "outputId": "cb17e624-0486-4273-b128-cfd446a0dc03"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Обучение и оценка\n",
    "=======================\n",
    "\n",
    "Имея все эти вспомогательные функции на месте (это выглядит как дополнительная работа, но\n",
    "упрощает проведение нескольких экспериментов), мы действительно можем\n",
    "инициализировать сеть и начать обучение.\n",
    "\n",
    "Помните, что вводимые предложения были тщательно отфильтрованы. Для этого небольшого\n",
    "набора данных мы можем использовать относительно небольшие сети из 256 скрытых узлов и\n",
    "одного уровня GRU. Примерно через 40 минут работы с процессором MacBook мы получим некоторые\n",
    "приемлемые результаты.\n",
    "\n",
    ".. Примечание::\n",
    "   Если вы запустите этот блокнот, вы сможете тренироваться, прерывать работу ядра,\n",
    "   оцените и продолжите обучение позже. Закомментируйте строки, в которых\n",
    "инициализируются кодер и декодер, и снова запустите `обучить других`.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, 10, print_every=1, plot_every=1)\n",
    "\n",
    "#\n",
    "# Set dropout layers to ``eval`` mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8vzgmRpGvCSU"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Визуализирующее внимание\n",
    "---------------------\n",
    "\n",
    "Полезным свойством механизма внимания является его легко интерпретируемая\n",
    "результативность. Поскольку он используется для взвешивания конкретных выходных данных кодера\n",
    "входной последовательности, мы можем представить, что смотрим, где сеть больше всего сосредоточена\n",
    "на каждом временном шаге.\n",
    "\n",
    "Вы могли бы просто запустить `plt.matshow(attentions)`, чтобы увидеть вывод внимания\n",
    ", отображаемый в виде матрицы. Для лучшего просмотра мы проделаем\n",
    "дополнительную работу по добавлению осей и меток:\n",
    "\"\"\"\n",
    "\n",
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "s7HGXd6lvCVe",
    "outputId": "c962ff2f-e07b-4b42-8bd0-d53006e0cf86"
   },
   "outputs": [],
   "source": [
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
    "\n",
    "\n",
    "evaluateAndShowAttention('he is not as tall as his father')\n",
    "\n",
    "evaluateAndShowAttention('i m too tired to drive')\n",
    "\n",
    "evaluateAndShowAttention('i m sorry if this is a silly question')\n",
    "\n",
    "evaluateAndShowAttention('i m really proud of you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "2QIVVZuyKcPP",
    "outputId": "65c21c08-2e95-41b6-d2ec-36523c5d3c07"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Упражнения\n",
    "=========\n",
    "\n",
    "-  Попробуйте использовать другой набор данных\n",
    "\n",
    "   -  Another language pair\n",
    "   -  Human → Machine (e.g. IOT commands)\n",
    "   -  Chat → Response\n",
    "   -  Question → Answer\n",
    "\n",
    "- Замените вложения предварительно подготовленными вложениями слов, такими как `word2vec` или\n",
    "   `Перчатка`\n",
    "- Попробуйте использовать больше слоев, больше скрытых единиц и больше предложений. Сравнивать\n",
    "   время тренировки и ее результаты.\n",
    "- Если вы используете файл перевода, в котором пары содержат две одинаковые фразы\n",
    "   (`I am test \\t I am test`), вы можете использовать это как автоэнкодер. Попробуй\n",
    "это:\n",
    "\n",
    "   - Тренируйтесь как автоэнкодер\n",
    "   - Сохранить только сеть кодировщика\n",
    "   - Обучите новый декодер для перевода оттуда\n",
    "\"\"\";"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
