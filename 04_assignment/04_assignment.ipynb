{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Важно!** \n",
    "\n",
    "Домашнее задание состоит из нескольких задач, которые вам нужно решить.\n",
    "*   Баллы выставляются по принципу выполнено/невыполнено.\n",
    "*   За каждую выполненую задачу вы получаете баллы (количество баллов за задание указано в скобках).\n",
    "\n",
    "**Инструкция выполнения:** Выполните задания в этом же ноутбуке (места под решения **КАЖДОЙ** задачи обозначены как **#НАЧАЛО ВАШЕГО РЕШЕНИЯ** и **#КОНЕЦ ВАШЕГО РЕШЕНИЯ**)\n",
    "\n",
    "**Как отправить задание на проверку:** Вам необходимо сохранить ваше решение в данном блокноте и отправить итоговый **файл .IPYNB** на учебной платформе в **стандартную форму сдачи домашнего задания.**\n",
    "\n",
    "**Срок проверки преподавателем:** домашнее задание проверяется **в течение 3 дней после дедлайна сдачи** с предоставлением обратной связи\n",
    "\n",
    "# **Прежде чем проверять задания:**\n",
    "\n",
    "1. Перезапустите **ядро (restart the kernel)**: в меню, выбрать **Ядро (Kernel)**\n",
    "→ **Перезапустить (Restart)**\n",
    "2. Затем **Выполнить** **все ячейки (run all cells)**: в меню, выбрать **Ячейка (Cell)**\n",
    "→ **Запустить все (Run All)**.\n",
    "\n",
    "После ячеек с заданием следуют ячейки с проверкой **с помощью assert.**\n",
    "\n",
    "Если в коде есть ошибки, assert выведет уведомление об ошибке.\n",
    "\n",
    "Если в коде нет ошибок, assert отработает без вывода дополнительной информации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Задание**\n",
    "\n",
    "В этом задании вам предстоит разобраться с энкодерами трансформеров на примере задач классификации и работы с различными моделями семейства BERT и XLNet. Задание состоит из трёх частей, каждая из которых поможет вам глубже понять работу трансформеров, их обучение и использование для решения задач обработки естественного языка (NLP).\n",
    "\n",
    "#### Часть 1: Классификация с использованием модели BERT и стандартного цикла обучения (без `Trainer`)\n",
    "1. В этой части вам необходимо решить задачу текстовой классификации (например, классификация отзывов на положительные и отрицательные) с использованием предобученной модели из семейства BERT (например, `bert-base-uncased`).\n",
    "2. Используйте стандартный цикл обучения, без использования класса `Trainer`. Это значит, что вы будете самостоятельно определять цикл обучения, включая шаги прямого прохода, вычисления функции потерь, обратного прохода и обновления весов модели.\n",
    "3. Краткое руководство:\n",
    "   - Загрузите датасет, подходящий для задачи классификации (например, IMDb или другой).\n",
    "   - Используйте библиотеку Huggingface `transformers` для загрузки модели и токенизатора.\n",
    "   - Реализуйте процесс токенизации входных данных и подготовки батчей.\n",
    "   - Напишите цикл обучения с использованием библиотеки `torch`:\n",
    "     - Прямой проход (forward pass) через модель.\n",
    "     - Вычисление функции потерь.\n",
    "     - Обратный проход (backward pass) и обновление весов.\n",
    "   - Оцените точность (accuracy) модели на тестовой выборке.\n",
    "\n",
    "#### Часть 2: Классификация с кастомной \"головой\" на базе BERT и использованием класса `Trainer`\n",
    "1. В этой части вам необходимо решить задачу классификации с использованием модели BERT, но с добавлением кастомной \"головы\" (custom head) — нового слоя или нескольких слоев поверх базовой модели BERT.\n",
    "2. Описание задачи:\n",
    "   - В качестве основы возьмите ту же модель `bert-base-uncased`, но добавьте свой собственный классификатор (например, дополнительные линейные слои или слои с нелинейностью).\n",
    "   - Используйте класс `Trainer` из библиотеки `transformers` для упрощения процесса обучения.\n",
    "   - Настройте гиперпараметры (шаг обучения, количество эпох и т.д.) и запустите обучение модели.\n",
    "3. Краткое руководство:\n",
    "   - Определите кастомную голову, которая будет использовать выходы последнего слоя BERT для классификации.\n",
    "   - Создайте новый класс, наследующий от `torch.nn.Module`, и включите в него кастомные слои.\n",
    "   - Настройте процесс обучения с помощью класса `Trainer`:\n",
    "     - Определите функции потерь и метрики.\n",
    "     - Укажите параметры оптимизатора и планировщика (scheduler).\n",
    "   - Оцените производительность модели с кастомной \"головой\" на тестовой выборке и сравните с результатами первой части.\n",
    "\n",
    "#### Часть 3: Сравнение метрик BERT и XLNet на задаче токен-классификации\n",
    "1. В этой части вам необходимо сравнить производительность двух моделей — BERT и XLNet — на задаче токен-классификации (например, задача распознавания именованных сущностей — Named Entity Recognition, NER).\n",
    "2. Задача:\n",
    "   - Возьмите готовый датасет для токен-классификации (например, CoNLL-2003 NER Dataset).\n",
    "   - Используйте модели BERT (`bert-base-cased`) и XLNet (`xlnet-base-cased`) для решения этой задачи.\n",
    "   - Обучите обе модели с использованием класса `Trainer` и сравните их производительность по метрикам точности (accuracy), полноты (recall), F1-меры.\n",
    "3. Краткое руководство:\n",
    "   - Загрузите и предобработайте данные для задачи токен-классификации (например, используя библиотеку `datasets`).\n",
    "   - Для каждой из моделей настройте обучение с использованием класса `Trainer`.\n",
    "   - Обучите модели и получите метрики на тестовой выборке.\n",
    "   - Сравните результаты: какие различия наблюдаются между производительностью BERT и XLNet на задаче токен-классификации? Как это можно объяснить с точки зрения архитектуры моделей?\n",
    "\n",
    "#### Ожидаемый результат:\n",
    "- Все задачи решаются в одном Jupyter notebook с подробным описанием процесса решения задачи, кодом и анализом результатов.\n",
    "- В третьей части задания необходимо сделать выводы по сравнению производительности моделей BERT и XLNet.\n",
    "- Включите графики метрик и таблицы результатов для наглядности.\n",
    "\n",
    "#### Ресурсы:\n",
    "- Библиотеки: `transformers`, `torch`, `datasets`, `numpy`, `pandas`.\n",
    "- Датасеты: IMDb (или любой другой для текстовой классификации), CoNLL-2003 для токен-классификации.\n",
    "\n",
    "\n",
    "Рекомендуемые ресурсы:\n",
    "- Документация Hugging Face Transformers https://huggingface.co/docs/transformers/index\n",
    "- Документация Hugging Face Datasets https://huggingface.co/docs/datasets/index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError() # удалить эту строку в процессе решения\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError() # удалить эту строку в процессе решения\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError() # удалить эту строку в процессе решения\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
